{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.output_parsers.json import parse_json_markdown\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "with open('openai_key.txt', encoding='utf-8') as f:\n",
    "    openai_key = f.readlines()[0]\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0, openai_api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(dictionary, argument):\n",
    "    dictionary['A'] = argument\n",
    "    keys = ['A'] + sorted(key for key in dictionary.keys() if key.startswith('P')) + ['C']\n",
    "    argument = \"\\n\".join(f\"{key}: {dictionary[key]}\" for key in keys)\n",
    "    return argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"####\"\n",
    "example = \"A: Climate has changed naturally in the past, so current climate change is natural.\\nP1: Climate has changed naturally in the past.\\nP2: Climate is changing now.\\nC: Therefore, current climate change is natural.\"\n",
    "argument = \"Environmentalists get science wrong as they are not committed to scientific principles. Therefore, environmentalists are biased and their reliability is questionable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\\\`\\\\`\\\\`json\" and \"\\\\`\\\\`\\\\`\":\\n\\n```json\\n{\\n\\t\"P#\": string  // premise of the argument\\n\\t\"C\": string  // conclusion of the argument\\n}\\n```'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"P#\", description=\"premise of the argument\"),\n",
    "    ResponseSchema(name=\"C\", description=\"conclusion of the argument\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argument', 'delimiter', 'example', 'format_instructions']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string = \"\"\"We are going to deconstruct climate misinformation to identify reasoning errors.\\\n",
    "To do so, we will break down arguments into their starting assumptions or premises and their conclusions.\\\n",
    "\\nFor example, argument A has two premises, P1 and P2, and a conclusion, C: {example}\n",
    "Using this structure, please identify the premises and conclusion of the following argument delimited by {delimiter}. \\\n",
    "{format_instructions}\\n\\\n",
    "{delimiter} {argument} {delimiter}\n",
    "\"\"\"\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(template_string)\n",
    "first_prompt.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"P#\": string  // premise of the argument\n",
      "\t\"C\": string  // conclusion of the argument\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P1': 'Environmentalists get science wrong as they are not committed to scientific principles.',\n",
       " 'C': 'Therefore, environmentalists are biased and their reliability is questionable.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=first_prompt)\n",
    "output_content = chain.run({'argument':argument, 'delimiter':delimiter, 'example':example, 'format_instructions':output_parser.get_format_instructions()})\n",
    "output = parse_json_markdown(output_content)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"\n",
    "Logically valid:\n",
    "A: 31,000 dissenting scientists prove there is no expert agreement on human-caused global warming\"\n",
    "P1: A large proportion of people with science degrees dissent human-caused global warming.\n",
    "P2: People with science degreess are experts on climante change.\n",
    "C: There is no expert agreement on human-caused global warming.\n",
    "\n",
    "TRUE, This argument is logically valid, if it was true that a large proportion of science graduates dissented and all those science graduates were climate experts then yes, it would follow that there was no expert consensus on climate change.\n",
    "\n",
    "Logically invalid: \n",
    "A: Climate has changed naturally in the past, so current climate change is natural.\n",
    "P1: Climate has changed naturally in the past.\n",
    "P2: Climate is changing now.\n",
    "C: Therefore, current climate change is natural.\n",
    "\n",
    "FALSE, This argument is logically invalid, just because the climate changed naturally in the past doesn't mean it's changing naturally now. \"\"\"\n",
    "\n",
    "template_string = \"\"\"Check if the argument delimited by {delimiter} is logically valid i.e. Does the conclusion follow from the premises?\n",
    "Assume that if all the premises are true, does it follow the conclusion is also true.\n",
    "Read the following examples before giving your answer, A: Argument, P#: Premises and C: Conclusion\n",
    "Examples: {example}\n",
    "\n",
    "{format_instructions}\\n\\\n",
    "\n",
    "{delimiter} {argument} {delimiter}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\\\`\\\\`\\\\`json\" and \"\\\\`\\\\`\\\\`\":\\n\\n```json\\n{\\n\\t\"valid\": string  // TRUE or FALSE\\n\\t\"reason\": string  // Explain your reasoning\\n}\\n```'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"valid\", description=\"TRUE or FALSE\"),\n",
    "    ResponseSchema(name=\"reason\", description=\"Explain your reasoning\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argument', 'delimiter', 'example', 'format_instructions']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(template_string)\n",
    "second_prompt.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'valid': 'TRUE',\n",
       " 'reason': 'The conclusion follows logically from the premise. If environmentalists are not committed to scientific principles and get science wrong, it is reasonable to conclude that they are biased and their reliability is questionable.'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=second_prompt)\n",
    "output_content = chain.run({'argument':print_dict(output, argument), 'delimiter':delimiter, 'example':example, 'format_instructions':output_parser.get_format_instructions()})\n",
    "output2 = parse_json_markdown(output_content)\n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"A: Climate has changed naturally in the past, so current climate change is natural.\\nP1: Climate has changed naturally in the past.\\nP2: Climate is changing now.\\nHP: If something wasn't a cause in the past, it can't be a cause now\\nC: Therefore, current climate change is natural.\"\n",
    "\n",
    "template_string = \"\"\"The conclusion of the argument delimited by {delimiter} doesn't follow from their premises, i.e. is logically invalid.\n",
    "We need to add an extra premise, an unstated assumption to make this argument logically valid. Follow the example bellow, A: Argument, P#: Premises, HP: Hidden premise C: Conclusion.\n",
    "Example: \n",
    "{example}\n",
    "\n",
    "{format_instructions}\\n\\\n",
    "\n",
    "{delimiter} {argument} {delimiter}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\\\`\\\\`\\\\`json\" and \"\\\\`\\\\`\\\\`\":\\n\\n```json\\n{\\n\\t\"HP\": string  // Hidden premise\\n}\\n```'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"HP\", description=\"Hidden premise\"),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argument', 'delimiter', 'example', 'format_instructions']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_prompt = ChatPromptTemplate.from_template(template_string)\n",
    "third_prompt.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP': 'If someone is not committed to scientific principles, their reliability is questionable.'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=third_prompt)\n",
    "output_content = chain.run({'argument':print_dict(output, argument), 'delimiter':delimiter, 'example':example, 'format_instructions':output_parser.get_format_instructions()})\n",
    "output3 = parse_json_markdown(output_content)\n",
    "output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['argument', 'delimiter', 'table']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_string = \"\"\"Is the argument indicated by {delimiter} subject to any of the fallacies outlined in the provided table?\\\n",
    "Thoroughly analyze each fallacy from the table, its definition and example before giving your answer.\\\n",
    "Please ensure to only use the options from the table and refrain from introducing new ones.\\\n",
    "If the argument is logically valid or it does not fall under any of the fallacies outlined, the response should be 'no fallacy'.\\\n",
    "If the argument exhibits any of the fallacies, the response should consist of a list of these fallacies, separated by commas (for example: foo, bar, baz).\\\n",
    "Please stick to the information requested and avoid including any extraneous details.\\\n",
    "\\n\n",
    "{table}\n",
    "\\n\n",
    "{delimiter} {argument} {delimiter}\n",
    "\"\"\"\n",
    "\n",
    "table = \"\"\"TECHNIQUE,DEFINITION,EXAMPLE\n",
    "Ad Hominem,\"Attacking a person/group instead of addressing their arguments.\",\"Climate science can't be trusted because climate scientists are biased.\"\n",
    "Ambiguity,\"Using ambiguous language in order to lead to a misleading conclusion.\",\"Thermometer readings have uncertainty which means we don't know whether global warming is happening.\"\n",
    "Anecdote,\"Using personal experience or isolated examples instead of sound arguments or compelling evidence.\",\"The weather is cold today—whatever happened to global warming?\"\n",
    "Blowfish,\"Focusing on an inconsequential aspect of scientific research, blowing it out of proportion in order to distract from or cast doubt on the main conclusions of the research.\",\"The hockey stick graph is invalid because it contains statistical errors.\"\n",
    "Bulk Fake Experts,\"Citing large numbers of seeming experts to argue that there is no scientific consensus on a topic.\",\"There is no expert consensus because 31,487 Americans with a science degree signed a petition saying humans aren't disrupting climate.\"\n",
    "Cherry Picking,\"Carefully selecting data that appear to confirm one position while ignoring other data that contradicts that position.\",\"Global warming stopped in 1998.\"\n",
    "Contradictory,\"Simultaneously believing in ideas that are mutually contradictory.\",\"The temperature record is fabricated by scientists… the temperature record shows cooling.\"\n",
    "Conspiracy Theory,\"Proposing that a secret plan exists to implement a nefarious scheme such as hiding a truth.\",\"The climategate emails prove that climate scientists have engaged in a conspiracy to deceive the public.\"\n",
    "Fake Debate,\"Presenting science and pseudoscience in an adversarial format to give the false impression of an ongoing scientific debate.\",\"Climate deniers should get equal coverage with climate scientists, providing a more balanced presentation of views.\"\n",
    "Fake Experts,\"Presenting an unqualified person or institution as a source of credible information.\",\"A retired physicist argues against the climate consensus, claiming the current weather change is just a natural occurrence.\"\n",
    "False Analogy,\"Assuming that because two things are alike in some ways, they are alike in some other respect.\",\"Climate sceptics are like Galileo who overturned the scientific consensus about geocentrism.\"\n",
    "False Choice,\"Presenting two options as the only possibilities, when other possibilities exist.\",\"CO2 lags temperature in the ice core record, proving that temperature drives CO2, not the other way around.\"\n",
    "False Equivalence (apples vs. oranges),\"Incorrectly claiming that two things are equivalent, despite the fact that there are notable differences between them.\",\"Why all the fuss about COVID when thousands die from the flu every year.\"\n",
    "Immune to evidence,\"Re-interpreting any evidence that counters a conspiracy theory as originating from the conspiracy.\",\"Those investigations finding climate scientists aren't conspiring were part of the conspiracy.\"\n",
    "Impossible Expectations,\"Demanding unrealistic standards of certainty before acting on the science.\",\"Scientists can't even predict the weather next week. How can they predict the climate in 100 years?\"\n",
    "Magnified Minority,\"Magnifying the significance of a handful of dissenting scientists to cast doubt on an overwhelming scientific consensus.\",\"Sure, there's 97% consensus but Professor Smith disagrees with the consensus position.\"\n",
    "Misrepresentation,\"Misrepresenting a situation or an opponent's position in such a way as to distort understanding.\",\"They changed the name from 'global warming' to 'climate change' because global warming stopped happening.\"\n",
    "Moving Goalposts,\"Demanding higher levels of evidence after receiving requested evidence.\",\"Sea levels may be rising but they're not accelerating.\"\n",
    "Nefarious intent,\"Assuming that the motivations behind any presumed conspiracy are nefarious.\",\"Climate scientists promote the climate hoax because they're in it for the money.\"\n",
    "Overriding suspicion,\"Having a nihilistic degree of scepticism towards the official account, preventing belief in anything that doesn't fit into the conspiracy theory.\",\"Show me one line of evidence for climate change... oh, that evidence is faked!\"\n",
    "Oversimplification,\"Simplifying a situation in such a way as to distort understanding, leading to erroneous conclusions.\",\"CO2 is plant food so burning fossil fuels will be good for plants.\"\n",
    "Persecuted victim,\"Perceiving and presenting themselves as the victim of organised persecution.\",\"Climate scientists are trying to take away our freedom.\"\n",
    "Quote Mining,\"Taking a person's words out-of-context in order to misrepresent their position.\",\"Mike's trick… to hide the decline.\"\n",
    "Re-interpreting randomness,\"Believing that nothing occurs by accident, so that random events are re-interpreted as being caused by the conspiracy.\",\"NASA's satellite exploded? They must be trying to hide inconvenient data!\"\n",
    "Red Herring,\"Deliberately diverting attention to an irrelevant point to distract from a more important point.\",\"CO2 is a trace gas so its warming effect is minimal.\"\n",
    "Single Cause,\"Assuming a single cause or reason when there might be multiple causes or reasons.\",\"Climate has changed naturally in the past so what's happening now must be natural.\"\n",
    "Slippery Slope,\"Suggesting that taking a minor action will inevitably lead to major consequences.\",\"If we implement even a modest climate policy, it will start us down the slippery slope to socialism and taking away our freedom.\"\n",
    "Slothful Induction,\"Ignoring relevant evidence when coming to a conclusion.\",\"There is no empirical evidence that humans are causing global warming.\"\n",
    "Something must be wrong,\"Maintaining that something must be wrong and the official account is based on deception, even when specific parts of a conspiracy theory become untenable.\",\"Ok, fine, 97% of climate scientists agree that humans are causing global warming, but that's just because they're toeing the party line.\"\n",
    "Straw Man,\"Misrepresenting or exaggerating an opponent's position to make it easier to attack.\",\"In the 1970s, climate scientists were predicting an ice age.\"\n",
    "\"\"\"\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_template(template_string)\n",
    "fourth_prompt.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad Hominem'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=fourth_prompt)\n",
    "output_content = chain.run({'argument':output['P1'], 'delimiter':delimiter, 'table':table})\n",
    "output_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ad Hominem']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()\n",
    "output_parser.parse(output_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_parser.parse(output_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debunking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
